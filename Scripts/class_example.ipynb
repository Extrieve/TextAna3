{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification using Gensim's Word2Vec and Doc2Vec models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: Titles and headlines from 93,239 news articles shared on Facebook, LinkedIn, and GooglePlus (we will use just news headlines and topics). Source: https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms\n",
    "\n",
    "Classifiers used: Stochastic Gradient Descent (SGD), MLPclassifier (neural network)\n",
    "\n",
    "Inputs used: Sentence vectors (as mean of word vectors), Doc2Vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink               float64\n",
       "Title                 object\n",
       "Headline              object\n",
       "Source                object\n",
       "Topic                 object\n",
       "PublishDate           object\n",
       "SentimentTitle       float64\n",
       "SentimentHeadline    float64\n",
       "Facebook               int64\n",
       "GooglePlus             int64\n",
       "LinkedIn               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('c:/Users/abhatt/Desktop/Text_Analytics/python/data/News_SocialMedia.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Title', 'Headline', 'Topic']]\n",
    "df = df.drop(df[df['Headline'].isna()].index, axis=0)   # 15 obs dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Note: simple_preprocess() normalizes cases, drops punctuations, and tokenizes\n",
    "# but does not remove stopwords or stem/lemmatize\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "tokenized_list = [simple_preprocess(h) for h in df['Headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d95e13a4e1c0>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  train_test_split(np.array(tokenized_list), np.array(df['Topic']),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((69918,), (23306,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test/train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_x, test_x, train_y, test_y = \\\n",
    "    train_test_split(np.array(tokenized_list), np.array(df['Topic']), \n",
    "    test_size=0.25, random_state=42)\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering using Word2Vec \n",
    "Word2Vec is Google's word vectorization model. In this approach, we will average word2vec vectors for all words in each title to compute a \"sentence vector\". This is not an ideal way to compute sentence vectors, doc2vec is a better approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24915"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec(train_x, window=8, min_count=2, sample=1e-3, sg=1, workers=8)\n",
    "vocab = set(w2v.wv.index_to_key)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "\n",
    "def average_word_vectors(tokens, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    ntokens = 0.\n",
    "    for t in tokens:\n",
    "        if t in vocabulary: \n",
    "            ntokens = ntokens + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[t])\n",
    "    if ntokens:\n",
    "        feature_vector = np.divide(feature_vector, ntokens)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (69918, 100) \n",
      "Test features shape: (23306, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v_train_x = [average_word_vectors(sent_tokens, w2v, vocab, num_features) \n",
    "               for sent_tokens in train_x]\n",
    "avg_w2v_train_x = np.array(w2v_train_x)\n",
    "\n",
    "w2v_test_x = [average_word_vectors(sent_tokens, w2v, vocab, num_features) \n",
    "              for sent_tokens in test_x]\n",
    "avg_w2v_test_x = np.array(w2v_test_x)\n",
    "\n",
    "print('Train features shape:', avg_w2v_train_x.shape, \n",
    "      '\\nTest features shape:', avg_w2v_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering using Doc2Vec\n",
    "Doc2Vec is Google's document vectorization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_x)]\n",
    "d2v = Doc2Vec(vector_size=100, window=3, min_count=4, workers=4, epochs=40)\n",
    "d2v.build_vocab(docs)\n",
    "d2v.train(docs, total_examples=d2v.corpus_count, epochs=d2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_train_x = [d2v.infer_vector(i) for i in train_x]\n",
    "d2v_test_x =  [d2v.infer_vector(i) for i in test_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using SGD classifier\n",
    "SGD (Stochastic Gradient Descent) is a single-layer neural network (perceptron, with no hidden layers). All neural networks require hyper-parameter tuning. The best way to do that is by using grid search. In this example, we are not doing that, but using fixed values of hyper-parameters instead. However, this example uses SGD with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=500)\n",
    "metrics = pd.DataFrame(columns=['Classification_Model', 'Training_Data', 'Recall', 'Precision', 'F1_Score'])\n",
    "\n",
    "train_x = [avg_w2v_train_x, d2v_train_x]\n",
    "test_x  = [avg_w2v_test_x,  d2v_test_x]\n",
    "input_model = ['Word2Vec', 'Doc2Vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input model: Word2Vec \n",
      "\n",
      "CV Accuracy (5-fold): [0.95995423 0.9597397  0.96124142 0.96173925 0.95973682]\n",
      "Mean CV Accuracy: 0.960482286557181\n",
      "Test Accuracy: 0.9618982236333992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       obama       0.96      0.96      0.96      8525\n",
      "     economy       0.97      0.97      0.97      5514\n",
      "   microsoft       0.96      0.96      0.96      7025\n",
      "   palestine       0.96      0.93      0.95      2242\n",
      "\n",
      "    accuracy                           0.96     23306\n",
      "   macro avg       0.96      0.96      0.96     23306\n",
      "weighted avg       0.96      0.96      0.96     23306\n",
      "\n",
      "Input model: Doc2Vec \n",
      "\n",
      "CV Accuracy (5-fold): [0.84854119 0.85018593 0.85633581 0.85561038 0.849174  ]\n",
      "Mean CV Accuracy: 0.8519694620191796\n",
      "Test Accuracy: 0.8363082468033982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       obama       0.81      0.87      0.84      8525\n",
      "     economy       0.87      0.86      0.86      5514\n",
      "   microsoft       0.83      0.84      0.84      7025\n",
      "   palestine       0.85      0.61      0.71      2242\n",
      "\n",
      "    accuracy                           0.84     23306\n",
      "   macro avg       0.84      0.80      0.82     23306\n",
      "weighted avg       0.84      0.84      0.83     23306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(train_x):\n",
    "    sgd.fit(x, train_y)\n",
    "    sgd_cv_accuracy = cross_val_score(sgd, x, train_y, cv=5)\n",
    "    print('Input model:', input_model[i], '\\n')\n",
    "    print('CV Accuracy (5-fold):', sgd_cv_accuracy)\n",
    "    \n",
    "    sgd_cv_mean_accuracy = np.mean(sgd_cv_accuracy)\n",
    "    print('Mean CV Accuracy:', sgd_cv_mean_accuracy)\n",
    "    \n",
    "    sgd_test_accuracy = sgd.score(test_x[i], test_y)\n",
    "    print('Test Accuracy:', sgd_test_accuracy)\n",
    "\n",
    "    pred_y = sgd.predict(test_x[i])\n",
    "    print(classification_report(test_y, pred_y, target_names=df['Topic'].unique()))\n",
    "\n",
    "    recall = recall_score(pred_y, test_y, average='weighted') \n",
    "    precision = precision_score(pred_y, test_y, average='weighted')  \n",
    "    f1score = f1_score(pred_y, test_y, average='weighted') \n",
    "    \n",
    "    metrics = metrics.append(pd.Series(['SGD Classifier', input_model[i], recall, \n",
    "                precision, f1score], index=metrics.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification_Model</th>\n",
       "      <th>Training_Data</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.961898</td>\n",
       "      <td>0.961983</td>\n",
       "      <td>0.961913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.843277</td>\n",
       "      <td>0.838011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification_Model Training_Data    Recall  Precision  F1_Score\n",
       "0       SGD Classifier      Word2Vec  0.961898   0.961983  0.961913\n",
       "1       SGD Classifier       Doc2Vec  0.836308   0.843277  0.838011"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.sort_values(['F1_Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using MLP classifier\n",
    "MLP classifier is a multi-layer neural network. Here, we use two hidden layers of 512 and 128 nodes. We are NOT doing k-fold cross-validation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512, 128), activation='relu', solver='adam', \n",
    "    learning_rate='adaptive', early_stopping=True, alpha=1e-5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9690637604050459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       obama       0.96      0.97      0.97      8525\n",
      "     economy       0.98      0.98      0.98      5514\n",
      "   microsoft       0.97      0.97      0.97      7025\n",
      "   palestine       0.96      0.95      0.96      2242\n",
      "\n",
      "    accuracy                           0.97     23306\n",
      "   macro avg       0.97      0.97      0.97     23306\n",
      "weighted avg       0.97      0.97      0.97     23306\n",
      "\n",
      "Test Accuracy: 0.8522698017677851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       obama       0.85      0.87      0.86      8525\n",
      "     economy       0.86      0.89      0.88      5514\n",
      "   microsoft       0.87      0.84      0.85      7025\n",
      "   palestine       0.79      0.74      0.77      2242\n",
      "\n",
      "    accuracy                           0.85     23306\n",
      "   macro avg       0.84      0.83      0.84     23306\n",
      "weighted avg       0.85      0.85      0.85     23306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(train_x):\n",
    "    mlp.fit(x, train_y)\n",
    "    mlp_test_accuracy = mlp.score(test_x[i], test_y)\n",
    "    print('Test Accuracy:', mlp_test_accuracy)    \n",
    "    \n",
    "    pred_y = mlp.predict(test_x[i])\n",
    "    print(classification_report(test_y, pred_y, target_names=df['Topic'].unique()))\n",
    "\n",
    "    recall = recall_score(pred_y, test_y, average='weighted') \n",
    "    precision = precision_score(pred_y, test_y, average='weighted')  \n",
    "    f1score = f1_score(pred_y, test_y, average='weighted') \n",
    "    \n",
    "    metrics = metrics.append(pd.Series(['MLP Classifier', input_model[i], recall, \n",
    "                precision, f1score], index=metrics.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification_Model</th>\n",
       "      <th>Training_Data</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.969064</td>\n",
       "      <td>0.969065</td>\n",
       "      <td>0.969057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.961898</td>\n",
       "      <td>0.961983</td>\n",
       "      <td>0.961913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>0.852270</td>\n",
       "      <td>0.853415</td>\n",
       "      <td>0.852623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.843277</td>\n",
       "      <td>0.838011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification_Model Training_Data    Recall  Precision  F1_Score\n",
       "2       MLP Classifier      Word2Vec  0.969064   0.969065  0.969057\n",
       "0       SGD Classifier      Word2Vec  0.961898   0.961983  0.961913\n",
       "3       MLP Classifier       Doc2Vec  0.852270   0.853415  0.852623\n",
       "1       SGD Classifier       Doc2Vec  0.836308   0.843277  0.838011"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.sort_values(['F1_Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data, Word2Vec outperforms Doc2Vec by a significant margin (0.97 to 0.85), and MLP outperforms SGD by a slight margin (0.97 to 0.96 or 0.85 to 0.84). This is surprising because we expected the average Word2Vec vector to be an inferior input compared to the Doc2Vec vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "85c576d62e5a69baba7dcae6282c7bf6fba6f8d537c9cbb11ca984aece3c77a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
